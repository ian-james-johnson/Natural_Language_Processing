{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63ecfd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "import unicodedata\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import acquire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65964fe5",
   "metadata": {},
   "source": [
    "1. Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "- Lowercase everything\n",
    "- Normalize unicode characters\n",
    "- Replace anything that is not a letter, number, whitespace or a single quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffebd95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(article):\n",
    "    \"\"\"\n",
    "    Lowercases, normalizes, and removes special characters from the article.\n",
    "    \"\"\"\n",
    "    # lowercasing\n",
    "    article = article.lower()\n",
    "    # normalize by removing non-ascii characters\n",
    "    # encode turns characters into ascii characters\n",
    "    # decode turns ascii characters back into a string\n",
    "    article = unicodedata.normalize('NFKD', article).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    # remove speial characters\n",
    "    article = re.sub(r'[^a-z09\\s]', '', article)\n",
    "    \n",
    "    return article"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f315b6ef",
   "metadata": {},
   "source": [
    "2. Define a function named tokenize. It should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c550e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(article):\n",
    "    \"\"\"\n",
    "    Tokenizes a cleaned article (or a string).\n",
    "    \"\"\"\n",
    "    # create the tokenizer\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    # use the tokenizer\n",
    "    article = tokenizer.tokenize(article, return_str=True)\n",
    "    \n",
    "    return article"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d9ea3c",
   "metadata": {},
   "source": [
    "3. Define a function named stem. It should accept some text and return the text after applying stemming to all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "595cde95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(article):\n",
    "    \"\"\"\n",
    "    Stem all words in an article (or a string).\n",
    "    \"\"\"\n",
    "    # create the stemmer\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    # use the stemmer, list comprehension uses the stemmer word-by-word\n",
    "    stems = [ps.stem(word) for word in article.split()]\n",
    "    # rejoin the stemmed words as an article\n",
    "    article_stemmed = ''.join(stems)\n",
    "    \n",
    "    return article_stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09194500",
   "metadata": {},
   "source": [
    "4. Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e8c18f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(article):\n",
    "    \"\"\"\n",
    "    Lemmatize all words in an article (or a string).\n",
    "    \"\"\"\n",
    "    # the the most current lemma list\n",
    "    nltk.download('wordnet')\n",
    "    # create the lemmatizer\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    # use the lemmatizer, list comprehension uses the lemmatizer word-by-word\n",
    "    lemmas = [wnl.lemmatize(word) for word in article.split()]\n",
    "    # rejoin the lemmatized words as a article\n",
    "    article_lemmatized = ''.join(lemmas)\n",
    "    \n",
    "    return article_lemmatized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f1790d",
   "metadata": {},
   "source": [
    "5. Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords. <br> <br>\n",
    "This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f541505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(article):\n",
    "    \"\"\"\n",
    "    Removes stopwords from an article (or a string).\n",
    "    \"\"\"\n",
    "    # get the default list of stopwords\n",
    "    stopword_list = stopwords.words('english')\n",
    "    # split the article to prepare for removal of stopwords\n",
    "    words = article.split()\n",
    "    # remove stopwords\n",
    "    filtered_stopwords = [word for word in words if word not in stopword_list]\n",
    "    # rejoin the words into article\n",
    "    article_without_stopwords = ''.join(filtered_stopwords)\n",
    "    \n",
    "    return article_without_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b8558a",
   "metadata": {},
   "source": [
    "6. Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe news_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae0b69a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>category</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Facebook changes its company name to 'Meta'</td>\n",
       "      <td>12:20 am</td>\n",
       "      <td>Business</td>\n",
       "      <td>Facebook on Thursday announced it's changing t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'Man who takes 6 months parental leave is a lo...</td>\n",
       "      <td>04:53 pm</td>\n",
       "      <td>Business</td>\n",
       "      <td>Several Twitter users criticised US-based Pala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Delhi HC notice to RBI, SBI over banning UPI p...</td>\n",
       "      <td>06:24 pm</td>\n",
       "      <td>Business</td>\n",
       "      <td>The Delhi High Court on Thursday issued notice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who are the top 10 new entrants on Hurun India...</td>\n",
       "      <td>04:46 pm</td>\n",
       "      <td>Business</td>\n",
       "      <td>Ace investor Rakesh Jhunjhunwala is the top ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indian market has 3 key beauties: Paytm CEO ah...</td>\n",
       "      <td>05:49 pm</td>\n",
       "      <td>Business</td>\n",
       "      <td>Vijay Shekhar Sharma, the CEO of Paytm that pl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline publish_time  category  \\\n",
       "0        Facebook changes its company name to 'Meta'     12:20 am  Business   \n",
       "1  'Man who takes 6 months parental leave is a lo...     04:53 pm  Business   \n",
       "2  Delhi HC notice to RBI, SBI over banning UPI p...     06:24 pm  Business   \n",
       "3  Who are the top 10 new entrants on Hurun India...     04:46 pm  Business   \n",
       "4  Indian market has 3 key beauties: Paytm CEO ah...     05:49 pm  Business   \n",
       "\n",
       "                                             content  \n",
       "0  Facebook on Thursday announced it's changing t...  \n",
       "1  Several Twitter users criticised US-based Pala...  \n",
       "2  The Delhi High Court on Thursday issued notice...  \n",
       "3  Ace investor Rakesh Jhunjhunwala is the top ne...  \n",
       "4  Vijay Shekhar Sharma, the CEO of Paytm that pl...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = acquire.get_news()\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3549c5",
   "metadata": {},
   "source": [
    "7. Make another dataframe for the Codeup blog posts. Name the dataframe codeup_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d41d9a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Codeup’s Data Science Career Accelerator is Here!</td>\n",
       "      <td>Sep 30, 2018</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>The rumors are true! The time has arrived. Cod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Myths</td>\n",
       "      <td>Oct 31, 2018</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>By Dimitri Antoniou and Maggie Giust Data Scie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science VS Data Analytics: What’s The Dif...</td>\n",
       "      <td>Oct 17, 2018</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>By Dimitri Antoniou A week ago, Codeup launche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 Tips to Crush It at the SA Tech Job Fair</td>\n",
       "      <td>Aug 14, 2018</td>\n",
       "      <td>Tips for Prospective Students</td>\n",
       "      <td>The third bi-annual San Antonio Tech Job Fair ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Competitor Bootcamps Are Closing. Is the Model...</td>\n",
       "      <td>Aug 14, 2018</td>\n",
       "      <td>Codeup News</td>\n",
       "      <td>In recent news, DevBootcamp and The Iron Yar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title          date  \\\n",
       "0  Codeup’s Data Science Career Accelerator is Here!  Sep 30, 2018   \n",
       "1                                 Data Science Myths  Oct 31, 2018   \n",
       "2  Data Science VS Data Analytics: What’s The Dif...  Oct 17, 2018   \n",
       "3        10 Tips to Crush It at the SA Tech Job Fair  Aug 14, 2018   \n",
       "4  Competitor Bootcamps Are Closing. Is the Model...  Aug 14, 2018   \n",
       "\n",
       "                        category  \\\n",
       "0                   Data Science   \n",
       "1                   Data Science   \n",
       "2                   Data Science   \n",
       "3  Tips for Prospective Students   \n",
       "4                    Codeup News   \n",
       "\n",
       "                                             content  \n",
       "0  The rumors are true! The time has arrived. Cod...  \n",
       "1  By Dimitri Antoniou and Maggie Giust Data Scie...  \n",
       "2  By Dimitri Antoniou A week ago, Codeup launche...  \n",
       "3  The third bi-annual San Antonio Tech Job Fair ...  \n",
       "4    In recent news, DevBootcamp and The Iron Yar...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codeup_df = acquire.get_blogs()\n",
    "codeup_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85496a50",
   "metadata": {},
   "source": [
    "8. For each dataframe, produce the following columns:\n",
    "- title to hold the title\n",
    "- original to hold the original article/post content\n",
    "- clean to hold the normalized and tokenized original with the stopwords removed.\n",
    "- stemmed to hold the stemmed version of the cleaned data.\n",
    "- lemmatized to hold the lemmatized version of the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7152aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>category</th>\n",
       "      <th>content</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Facebook changes its company name to 'Meta'</td>\n",
       "      <td>12:20 am</td>\n",
       "      <td>Business</td>\n",
       "      <td>Facebook on Thursday announced it's changing t...</td>\n",
       "      <td>facebook on thursday announced its changing th...</td>\n",
       "      <td>facebookonthursdayannouncitchangthecompaniname...</td>\n",
       "      <td>facebookonthursdayannounceditchangingthecompan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'Man who takes 6 months parental leave is a lo...</td>\n",
       "      <td>04:53 pm</td>\n",
       "      <td>Business</td>\n",
       "      <td>Several Twitter users criticised US-based Pala...</td>\n",
       "      <td>several twitter users criticised usbased palan...</td>\n",
       "      <td>severtwitterusercriticisusbaspalantirtechnolog...</td>\n",
       "      <td>severaltwitterusercriticisedusbasedpalantirtec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Delhi HC notice to RBI, SBI over banning UPI p...</td>\n",
       "      <td>06:24 pm</td>\n",
       "      <td>Business</td>\n",
       "      <td>The Delhi High Court on Thursday issued notice...</td>\n",
       "      <td>the delhi high court on thursday issued notice...</td>\n",
       "      <td>thedelhihighcourtonthursdayissunotictorbisbinp...</td>\n",
       "      <td>thedelhihighcourtonthursdayissuednoticetorbisb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who are the top 10 new entrants on Hurun India...</td>\n",
       "      <td>04:46 pm</td>\n",
       "      <td>Business</td>\n",
       "      <td>Ace investor Rakesh Jhunjhunwala is the top ne...</td>\n",
       "      <td>ace investor rakesh jhunjhunwala is the top ne...</td>\n",
       "      <td>aceinvestorrakeshjhunjhunwalaisthetopnewentran...</td>\n",
       "      <td>aceinvestorrakeshjhunjhunwalaisthetopnewentran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indian market has 3 key beauties: Paytm CEO ah...</td>\n",
       "      <td>05:49 pm</td>\n",
       "      <td>Business</td>\n",
       "      <td>Vijay Shekhar Sharma, the CEO of Paytm that pl...</td>\n",
       "      <td>vijay shekhar sharma the ceo of paytm that pla...</td>\n",
       "      <td>vijayshekharsharmatheceoofpaytmthatplantorais0...</td>\n",
       "      <td>vijayshekharsharmatheceoofpaytmthatplantoraise...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline publish_time  category  \\\n",
       "0        Facebook changes its company name to 'Meta'     12:20 am  Business   \n",
       "1  'Man who takes 6 months parental leave is a lo...     04:53 pm  Business   \n",
       "2  Delhi HC notice to RBI, SBI over banning UPI p...     06:24 pm  Business   \n",
       "3  Who are the top 10 new entrants on Hurun India...     04:46 pm  Business   \n",
       "4  Indian market has 3 key beauties: Paytm CEO ah...     05:49 pm  Business   \n",
       "\n",
       "                                             content  \\\n",
       "0  Facebook on Thursday announced it's changing t...   \n",
       "1  Several Twitter users criticised US-based Pala...   \n",
       "2  The Delhi High Court on Thursday issued notice...   \n",
       "3  Ace investor Rakesh Jhunjhunwala is the top ne...   \n",
       "4  Vijay Shekhar Sharma, the CEO of Paytm that pl...   \n",
       "\n",
       "                                             cleaned  \\\n",
       "0  facebook on thursday announced its changing th...   \n",
       "1  several twitter users criticised usbased palan...   \n",
       "2  the delhi high court on thursday issued notice...   \n",
       "3  ace investor rakesh jhunjhunwala is the top ne...   \n",
       "4  vijay shekhar sharma the ceo of paytm that pla...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  facebookonthursdayannouncitchangthecompaniname...   \n",
       "1  severtwitterusercriticisusbaspalantirtechnolog...   \n",
       "2  thedelhihighcourtonthursdayissunotictorbisbinp...   \n",
       "3  aceinvestorrakeshjhunjhunwalaisthetopnewentran...   \n",
       "4  vijayshekharsharmatheceoofpaytmthatplantorais0...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  facebookonthursdayannounceditchangingthecompan...  \n",
       "1  severaltwitterusercriticisedusbasedpalantirtec...  \n",
       "2  thedelhihighcourtonthursdayissuednoticetorbisb...  \n",
       "3  aceinvestorrakeshjhunjhunwalaisthetopnewentran...  \n",
       "4  vijayshekharsharmatheceoofpaytmthatplantoraise...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df['cleaned'] = news_df['content'].apply(basic_clean).apply(tokenize)\n",
    "news_df['stemmed'] = news_df['cleaned'].apply(stem)\n",
    "news_df['lemmatized'] = news_df['cleaned'].apply(lemmatize)\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a7b85a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ianjohnson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>content</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Codeup’s Data Science Career Accelerator is Here!</td>\n",
       "      <td>Sep 30, 2018</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>The rumors are true! The time has arrived. Cod...</td>\n",
       "      <td>the rumors are true the time has arrived codeu...</td>\n",
       "      <td>therumoraretruethetimehaarrivcodeuphaofficiope...</td>\n",
       "      <td>therumoraretruethetimehaarrivedcodeuphaofficia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Myths</td>\n",
       "      <td>Oct 31, 2018</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>By Dimitri Antoniou and Maggie Giust Data Scie...</td>\n",
       "      <td>by dimitri antoniou and maggie giust data scie...</td>\n",
       "      <td>bydimitriantoniandmaggigiustdatasciencbigdatam...</td>\n",
       "      <td>bydimitriantoniouandmaggiegiustdatasciencebigd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science VS Data Analytics: What’s The Dif...</td>\n",
       "      <td>Oct 17, 2018</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>By Dimitri Antoniou A week ago, Codeup launche...</td>\n",
       "      <td>by dimitri antoniou a week ago codeup launched...</td>\n",
       "      <td>bydimitriantoniaweekagocodeuplaunchourimmersda...</td>\n",
       "      <td>bydimitriantoniouaweekagocodeuplaunchedourimme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 Tips to Crush It at the SA Tech Job Fair</td>\n",
       "      <td>Aug 14, 2018</td>\n",
       "      <td>Tips for Prospective Students</td>\n",
       "      <td>The third bi-annual San Antonio Tech Job Fair ...</td>\n",
       "      <td>the third biannual san antonio tech job fair i...</td>\n",
       "      <td>thethirdbiannualsanantoniotechjobfairisjustaro...</td>\n",
       "      <td>thethirdbiannualsanantoniotechjobfairisjustaro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Competitor Bootcamps Are Closing. Is the Model...</td>\n",
       "      <td>Aug 14, 2018</td>\n",
       "      <td>Codeup News</td>\n",
       "      <td>In recent news, DevBootcamp and The Iron Yar...</td>\n",
       "      <td>in recent news devbootcamp and the iron yard a...</td>\n",
       "      <td>inrecentnewsdevbootcampandtheironyardannouncth...</td>\n",
       "      <td>inrecentnewsdevbootcampandtheironyardannounced...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title          date  \\\n",
       "0  Codeup’s Data Science Career Accelerator is Here!  Sep 30, 2018   \n",
       "1                                 Data Science Myths  Oct 31, 2018   \n",
       "2  Data Science VS Data Analytics: What’s The Dif...  Oct 17, 2018   \n",
       "3        10 Tips to Crush It at the SA Tech Job Fair  Aug 14, 2018   \n",
       "4  Competitor Bootcamps Are Closing. Is the Model...  Aug 14, 2018   \n",
       "\n",
       "                        category  \\\n",
       "0                   Data Science   \n",
       "1                   Data Science   \n",
       "2                   Data Science   \n",
       "3  Tips for Prospective Students   \n",
       "4                    Codeup News   \n",
       "\n",
       "                                             content  \\\n",
       "0  The rumors are true! The time has arrived. Cod...   \n",
       "1  By Dimitri Antoniou and Maggie Giust Data Scie...   \n",
       "2  By Dimitri Antoniou A week ago, Codeup launche...   \n",
       "3  The third bi-annual San Antonio Tech Job Fair ...   \n",
       "4    In recent news, DevBootcamp and The Iron Yar...   \n",
       "\n",
       "                                             cleaned  \\\n",
       "0  the rumors are true the time has arrived codeu...   \n",
       "1  by dimitri antoniou and maggie giust data scie...   \n",
       "2  by dimitri antoniou a week ago codeup launched...   \n",
       "3  the third biannual san antonio tech job fair i...   \n",
       "4  in recent news devbootcamp and the iron yard a...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  therumoraretruethetimehaarrivcodeuphaofficiope...   \n",
       "1  bydimitriantoniandmaggigiustdatasciencbigdatam...   \n",
       "2  bydimitriantoniaweekagocodeuplaunchourimmersda...   \n",
       "3  thethirdbiannualsanantoniotechjobfairisjustaro...   \n",
       "4  inrecentnewsdevbootcampandtheironyardannouncth...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  therumoraretruethetimehaarrivedcodeuphaofficia...  \n",
       "1  bydimitriantoniouandmaggiegiustdatasciencebigd...  \n",
       "2  bydimitriantoniouaweekagocodeuplaunchedourimme...  \n",
       "3  thethirdbiannualsanantoniotechjobfairisjustaro...  \n",
       "4  inrecentnewsdevbootcampandtheironyardannounced...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codeup_df['cleaned'] = codeup_df['content'].apply(basic_clean).apply(tokenize)\n",
    "codeup_df['stemmed'] = codeup_df['cleaned'].apply(stem)\n",
    "codeup_df['lemmatized'] = codeup_df['cleaned'].apply(lemmatize)\n",
    "codeup_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac57d583",
   "metadata": {},
   "source": [
    "9. Ask yourself:<br>\n",
    "\n",
    "If your corpus is 493KB, would you prefer to use stemmed or lemmatized text? <br>\n",
    "We can afford to use lemmatization instead of stemming; because the corpus size is small and therefore the computational cost is also small. <br> <br>\n",
    "If your corpus is 25MB, would you prefer to use stemmed or lemmatized text? <br>\n",
    "I might use stemming because the larger corpus size incurs a larger computational cost. <br> <br>\n",
    "If your corpus is 200TB of text and you're charged by the megabyte for your hosted computational resources, would you prefer to use stemmed or lemmatized text? <br>\n",
    "I would definitely use stemmed text in order to reduce the computational cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24751270",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
